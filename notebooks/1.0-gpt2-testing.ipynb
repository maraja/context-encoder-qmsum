{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c690db39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# Run if working locally\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# Run if working locally\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run if working locally\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45073e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import sqlite3\\nfrom sqlite3 import Error\\nimport pickle\\nimport os, sys\\nimport config\\n\\nconfig.root_path = os.path.abspath(os.path.join(os.getcwd(), \\\"..\\\"))\\nsys.path.insert(0, config.root_path)\\n\\nfrom db.dbv2 import Table, AugmentedTable, TrainTestTable\";\n",
       "                var nbb_formatted_code = \"import sqlite3\\nfrom sqlite3 import Error\\nimport pickle\\nimport os, sys\\nimport config\\n\\nconfig.root_path = os.path.abspath(os.path.join(os.getcwd(), \\\"..\\\"))\\nsys.path.insert(0, config.root_path)\\n\\nfrom db.dbv2 import Table, AugmentedTable, TrainTestTable\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pickle\n",
    "import os, sys\n",
    "import config\n",
    "\n",
    "config.root_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, config.root_path)\n",
    "\n",
    "from db.dbv2 import Table, AugmentedTable, TrainTestTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df955bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 17:20:13.813491: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-30 17:20:13.813738: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"from src.dataset.gpt_augmentor import Augmentor\";\n",
       "                var nbb_formatted_code = \"from src.dataset.gpt_augmentor import Augmentor\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.dataset.gpt_augmentor import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c581606b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport nltk\\nfrom nltk.tokenize import word_tokenize\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport nltk\\nfrom nltk.tokenize import word_tokenize\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0014f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"dataset_type = \\\"committee\\\"\\n\\ntable = Table(dataset_type)\\naugmented_table = AugmentedTable(dataset_type)\\ntrain_test_table = TrainTestTable(dataset_type)\";\n",
       "                var nbb_formatted_code = \"dataset_type = \\\"committee\\\"\\n\\ntable = Table(dataset_type)\\naugmented_table = AugmentedTable(dataset_type)\\ntrain_test_table = TrainTestTable(dataset_type)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_type = \"committee\"\n",
    "\n",
    "table = Table(dataset_type)\n",
    "augmented_table = AugmentedTable(dataset_type)\n",
    "train_test_table = TrainTestTable(dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3a53e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed augmenting 1/2...\n",
      "Completed augmenting 2/2...\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"min_sent_tokens = 8\\nmax_sent_tokens = 64\\n\\ntarget_sentences_original = table.get_target_sentences()\\ntarget_sentences = [s[1] for s in target_sentences_original]\\ncleaned_target_sentences = []\\n\\nfor s in target_sentences:\\n    if len(word_tokenize(s)) > min_sent_tokens:\\n        shortened_sentence = \\\" \\\".join(word_tokenize(s)[:max_sent_tokens])\\n        cleaned_target_sentences.append(shortened_sentence)\\n\\naugmented_segments = Augmentor.augment_gpt2(\\n    cleaned_target_sentences[:2],\\n    fast=True,\\n    # multiply by 5 to account for 5 as a max segment\\n    max_seq_word_length=max_sent_tokens * 5,\\n    verbose=True,\\n)\";\n",
       "                var nbb_formatted_code = \"min_sent_tokens = 8\\nmax_sent_tokens = 64\\n\\ntarget_sentences_original = table.get_target_sentences()\\ntarget_sentences = [s[1] for s in target_sentences_original]\\ncleaned_target_sentences = []\\n\\nfor s in target_sentences:\\n    if len(word_tokenize(s)) > min_sent_tokens:\\n        shortened_sentence = \\\" \\\".join(word_tokenize(s)[:max_sent_tokens])\\n        cleaned_target_sentences.append(shortened_sentence)\\n\\naugmented_segments = Augmentor.augment_gpt2(\\n    cleaned_target_sentences[:2],\\n    fast=True,\\n    # multiply by 5 to account for 5 as a max segment\\n    max_seq_word_length=max_sent_tokens * 5,\\n    verbose=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_sent_tokens = 8\n",
    "max_sent_tokens = 64\n",
    "\n",
    "target_sentences_original = table.get_target_sentences()\n",
    "target_sentences = [s[1] for s in target_sentences_original]\n",
    "cleaned_target_sentences = []\n",
    "\n",
    "for s in target_sentences:\n",
    "    if len(word_tokenize(s)) > min_sent_tokens:\n",
    "        shortened_sentence = \" \".join(word_tokenize(s)[:max_sent_tokens])\n",
    "        cleaned_target_sentences.append(shortened_sentence)\n",
    "\n",
    "augmented_segments = Augmentor.augment_gpt2(\n",
    "    cleaned_target_sentences[:2],\n",
    "    fast=True,\n",
    "    # multiply by 5 to account for 5 as a max segment\n",
    "    max_seq_word_length=max_sent_tokens * 5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a667f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_target_sentences[:1], augmented_segments[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d355711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
