{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdeb3c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# Run if working locally\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# Run if working locally\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run if working locally\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfcc4c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import config\\nimport sys\\nimport os\\n\\nconfig.root_path = os.path.abspath(os.path.join(os.getcwd(), \\\"..\\\"))\\nsys.path.insert(0, config.root_path)\\n\\nfrom src.experimentation.ldabert import SimpleExperiment\";\n",
       "                var nbb_formatted_code = \"import config\\nimport sys\\nimport os\\n\\nconfig.root_path = os.path.abspath(os.path.join(os.getcwd(), \\\"..\\\"))\\nsys.path.insert(0, config.root_path)\\n\\nfrom src.experimentation.ldabert import SimpleExperiment\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import config\n",
    "import sys\n",
    "import os\n",
    "\n",
    "config.root_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, config.root_path)\n",
    "\n",
    "from src.experimentation.ldabert import SimpleExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423de63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"experiment = SimpleExperiment(experiment_string=\\\"ldabert2_simple_lib_test\\\")\";\n",
       "                var nbb_formatted_code = \"experiment = SimpleExperiment(experiment_string=\\\"ldabert2_simple_lib_test\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment = SimpleExperiment(experiment_string=\"ldabert2_simple_lib_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93449ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training params: {'bert_type': 'ldabert', 'dataset_type': 'committee', 'final_dropout': 0.5, 'dense_neurons': 128, 'max_sentence_length': 128, 'gamma': 15, 'pct_data': 0.01, 'augment_pct': 0, 'bert_trainable': False, 'epochs': 1}\n",
      "initializing model...\n",
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 21:24:00.577140: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-01 21:24:00.577432: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing dataset...\n",
      "processing dataset...\n",
      "initializing validation dataset...\n",
      "processing validation dataset...\n",
      "class weight {0: 0.51875, 1: 13.833333333333332}\n",
      "/Users/amitmaraj/Documents/PhD/context-encoder-qmsum/models/LDABERT2/simple/committee-62-0.01-pct-0-aug_R4Ldh/no-finetune/checkpoint.ckpt\n",
      "compiling the model...\n",
      "No checkpoint available.\n",
      "starting the training process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 21:24:05.286043: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-01-01 21:24:17.152063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.9094 - accuracy: 0.5953 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 21:24:29.513651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 342s 325s/step - loss: 0.9094 - accuracy: 0.5953 - val_loss: 0.5538 - val_accuracy: 0.8105\n",
      "saving results...\n",
      "Conducting predictions - initializing testing dataset...\n",
      "processing testing dataset...\n",
      "0 125\n",
      "125 250\n",
      "250 375\n",
      "375 500\n",
      "500 625\n",
      "625 750\n",
      "750 875\n",
      "875 1000\n",
      "1000 1125\n",
      "1125 1250\n",
      "1250 1375\n",
      "1375 1500\n",
      "1500 1625\n",
      "1625 1750\n",
      "1750 1875\n",
      "1875 2000\n",
      "2000 2125\n",
      "2125 2250\n",
      "2250 2375\n",
      "2375 2500\n",
      "2500 2625\n",
      "2625 2750\n",
      "2750 2875\n",
      "2875 3000\n",
      "3000 3125\n",
      "3125 3250\n",
      "3250 3375\n",
      "3375 3500\n",
      "3500 3625\n",
      "3625 3750\n",
      "3750 3875\n",
      "3875 4000\n",
      "4000 4125\n",
      "4125 4250\n",
      "4250 4375\n",
      "training params: {'bert_type': 'ldabert', 'dataset_type': 'product', 'final_dropout': 0.5, 'dense_neurons': 128, 'max_sentence_length': 128, 'gamma': 15, 'pct_data': 0.01, 'augment_pct': 0, 'bert_trainable': False, 'epochs': 1}\n",
      "initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing dataset...\n",
      "processing dataset...\n",
      "initializing validation dataset...\n",
      "processing validation dataset...\n",
      "class weight {0: 0.5047961630695443, 1: 52.625}\n",
      "/Users/amitmaraj/Documents/PhD/context-encoder-qmsum/models/LDABERT2/simple/product-478-0.01-pct-0-aug_BPqEB/no-finetune/checkpoint.ckpt\n",
      "compiling the model...\n",
      "No checkpoint available.\n",
      "starting the training process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 21:35:58.241491: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 1.1312 - accuracy: 0.5859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 21:36:45.711252: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2761s 196s/step - loss: 1.1312 - accuracy: 0.5859 - val_loss: 0.7411 - val_accuracy: 0.4220\n",
      "saving results...\n",
      "Conducting predictions - initializing testing dataset...\n",
      "processing testing dataset...\n",
      "something went wrong [Errno 2] No such file or directory: '/Users/amitmaraj/Documents/PhD/context-encoder-qmsum/data/lda_bert_2/generated_vectors/test/product/1_0_testing_data.pkl'\n",
      "root path /Users/amitmaraj/Documents/PhD/context-encoder-qmsum\n",
      "Preprocessing raw texts ...\n",
      "sentences length 25335\n",
      "Preprocessing raw texts. Done!\n",
      "lda sentences length 25335\n",
      "Getting vector representations for LDA ...\n",
      "Getting vector representations for LDA. Done!\n",
      "saving vectors... 25335 25335 25335\n",
      "0 125\n",
      "125 250\n",
      "250 375\n",
      "375 500\n",
      "500 625\n",
      "625 750\n",
      "750 875\n",
      "875 1000\n",
      "1000 1125\n",
      "1125 1250\n",
      "1250 1375\n",
      "1375 1500\n",
      "1500 1625\n",
      "1625 1750\n",
      "1750 1875\n",
      "1875 2000\n",
      "2000 2125\n",
      "2125 2250\n",
      "2250 2375\n",
      "2375 2500\n",
      "2500 2625\n",
      "2625 2750\n",
      "2750 2875\n",
      "2875 3000\n",
      "3000 3125\n",
      "3125 3250\n",
      "3250 3375\n",
      "3375 3500\n",
      "3500 3625\n",
      "3625 3750\n",
      "3750 3875\n",
      "3875 4000\n",
      "4000 4125\n",
      "4125 4250\n",
      "4250 4375\n",
      "4375 4500\n",
      "4500 4625\n",
      "4625 4750\n",
      "4750 4875\n",
      "4875 5000\n",
      "5000 5125\n",
      "5125 5250\n",
      "5250 5375\n",
      "5375 5500\n",
      "5500 5625\n",
      "5625 5750\n",
      "5750 5875\n",
      "5875 6000\n",
      "6000 6125\n",
      "6125 6250\n",
      "6250 6375\n",
      "6375 6500\n",
      "6500 6625\n",
      "6625 6750\n",
      "6750 6875\n",
      "6875 7000\n",
      "7000 7125\n",
      "7125 7250\n",
      "7250 7375\n",
      "7375 7500\n",
      "7500 7625\n",
      "7625 7750\n",
      "7750 7875\n",
      "7875 8000\n",
      "8000 8125\n",
      "8125 8250\n",
      "8250 8375\n",
      "8375 8500\n",
      "8500 8625\n",
      "8625 8750\n",
      "8750 8875\n",
      "8875 9000\n",
      "9000 9125\n",
      "9125 9250\n",
      "9250 9375\n",
      "9375 9500\n",
      "9500 9625\n",
      "9625 9750\n",
      "9750 9875\n",
      "9875 10000\n",
      "10000 10125\n",
      "10125 10250\n",
      "10250 10375\n",
      "10375 10500\n",
      "10500 10625\n",
      "10625 10750\n",
      "10750 10875\n",
      "10875 11000\n",
      "11000 11125\n",
      "11125 11250\n",
      "11250 11375\n",
      "11375 11500\n",
      "11500 11625\n",
      "11625 11750\n",
      "11750 11875\n",
      "11875 12000\n",
      "12000 12125\n",
      "12125 12250\n",
      "12250 12375\n",
      "12375 12500\n",
      "12500 12625\n",
      "12625 12750\n",
      "12750 12875\n",
      "12875 13000\n",
      "13000 13125\n",
      "13125 13250\n",
      "13250 13375\n",
      "13375 13500\n",
      "13500 13625\n",
      "13625 13750\n",
      "13750 13875\n",
      "13875 14000\n",
      "14000 14125\n",
      "14125 14250\n",
      "14250 14375\n",
      "14375 14500\n",
      "14500 14625\n",
      "14625 14750\n",
      "14750 14875\n",
      "14875 15000\n",
      "15000 15125\n",
      "15125 15250\n",
      "15250 15375\n",
      "15375 15500\n",
      "15500 15625\n",
      "15625 15750\n",
      "15750 15875\n",
      "15875 16000\n",
      "16000 16125\n",
      "16125 16250\n",
      "16250 16375\n",
      "16375 16500\n",
      "16500 16625\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1933b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
